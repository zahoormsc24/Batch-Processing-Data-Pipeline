# ğŸ›’ Batch Data Pipeline for Retail Analytics

A Dockerized **batch-processing** pipeline that ingests, cleans, and aggregates retail transactions for **quarterly analytics**.  
Built with **Laravel**, **MySQL**, and **Docker** using a microservices approach.

> **Course:** Data Engineering (DLMDSEDE02) â€” Portfolio Project  
> **Phase:** Development/Reflection (Phase 2) âœ”ï¸

---

## ğŸ“‚ Repository
**GitHub:** [Batch-Processing-Data-Pipeline](https://github.com/zahoormsc24/Batch-Processing-Data-Pipeline)

---

## ğŸ“š Table of Contents
1. [Overview](#-overview)  
2. [Architecture](#-architecture)  
3. [Repository Structure](#-repository-structure)  
4. [Prerequisites](#-prerequisites)  
5. [Quickstart](#-quickstart)  
   - [A. Using This Repository](#a-using-this-repository)  
   - [B. Starting From Scratch](#b-starting-from-scratch)  
6. [Configuration](#-configuration)  
7. [Database Schema](#-database-schema)  
8. [Running the Pipeline](#-running-the-pipeline)  
9. [Troubleshooting](#-troubleshooting)  
10. [Roadmap](#-roadmap)  
11. [License & Acknowledgements](#-license--acknowledgements)  
12. [Maintainer](#-maintainer)

---

## ğŸ” Overview
This repository implements a **batch data pipeline** for the UCI **Online Retail II** dataset (1M+ time-referenced transactions).  

The pipeline:
- **Ingests** CSV data into MySQL (`transactions` table)  
- **Cleans** invalid rows (`clean_transactions` table)  
- **Aggregates** quarterly sales per product & customer (`quarterly_sales` table)  

It is designed for **reliability**, **reproducibility**, and **maintainability**, using **Docker Compose**, **Laravel Artisan commands**, and **database migrations**.

---

## ğŸ— Architecture
*(Insert your architecture diagram in `docs/architecture.png` once ready)*

**Pipeline Flow:**
Excel (.xlsx) â†’ CSV â†’ ingestion â†’ transactions
â†“
preprocessing â†’ clean_transactions
â†“
aggregation â†’ quarterly_sales


**Services**
- **MySQL** â€“ central database  
- **Ingestion** â€“ loads CSV â†’ transactions  
- **Preprocessing** â€“ filters invalid rows â†’ clean_transactions  
- **Aggregation** â€“ computes quarterly sales â†’ quarterly_sales  

---

## ğŸ“ Repository Structure
Batch-Processing-Data-Pipeline/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docs/
â”‚ â””â”€â”€ architecture.png
â”œâ”€â”€ ingestion/ # Laravel app (commands + migrations)
â”‚ â”œâ”€â”€ app/Console/Commands/
â”‚ â”‚ â”œâ”€â”€ IngestCsv.php
â”‚ â”‚ â”œâ”€â”€ PreprocessData.php
â”‚ â”‚ â””â”€â”€ AggregateQuarterly.php
â”‚ â”œâ”€â”€ database/migrations/
â”‚ â”‚ â”œâ”€â”€ create_transactions_table.php
â”‚ â”‚ â”œâ”€â”€ create_clean_transactions_table.php
â”‚ â”‚ â””â”€â”€ create_quarterly_sales_table.php
â”‚ â””â”€â”€ storage/app/online_retail_II.csv


---

## âœ… Prerequisites
- Docker & Docker Compose  
- PHP 8.x & Composer (if running Laravel locally)  
- LibreOffice (for `.xlsx â†’ .csv`) or manual CSV export  

---

## âš¡ Quickstart

### A) Using This Repository
```bash
# Clone repo
git clone https://github.com/zahoormsc24/Batch-Processing-Data-Pipeline.git
cd Batch-Processing-Data-Pipeline

# Start containers
docker compose up -d --build

# Enter Laravel app container
docker compose exec ingestion bash

# Run migrations
php artisan migrate

# Place CSV file into:
#   host:   ingestion/storage/app/online_retail_II.csv
#   inside: storage/app/online_retail_II.csv

# Run pipeline
php artisan ingest:csv
php artisan preprocess:data
php artisan aggregate:quarterly
```
B) Starting From Scratch
mkdir retail-pipeline && cd retail-pipeline
composer create-project laravel/laravel ingestion

# Convert dataset to CSV
libreoffice --headless --convert-to csv online_retail_II.xlsx

# Write docker-compose.yml and repeat steps above

âš™ï¸ Configuration
.env (inside ingestion container):
DB_CONNECTION=mysql
DB_HOST=mysql
DB_PORT=3306       # inside containers
DB_DATABASE=retail_db
DB_USERNAME=retail_user
DB_PASSWORD=retail_pass

Host MySQL access:
Host: 127.0.0.1

Port: 3307 (mapped in docker-compose.yml)

User: retail_user

Pass: retail_pass

ğŸ—„ Database Schema
transactions (raw data)
| Column      | Type    | Notes                  |
| ----------- | ------- | ---------------------- |
| Invoice     | string  | Invoice number         |
| StockCode   | string  | Product code           |
| Description | string  | Product description    |
| Quantity    | int     | Quantity purchased     |
| InvoiceDate | string  | Transaction date/time  |
| Price       | decimal | Price per unit         |
| CustomerID  | string  | Customer ID (nullable) |
| Country     | string  | Customer country       |

clean_transactions (validated data)
Same schema as transactions, excluding invalid rows.
quarterly_sales (aggregated data)
| Column          | Type    | Notes                     |
| --------------- | ------- | ------------------------- |
| year\_quarter   | string  | e.g., `2011-Q1`           |
| StockCode       | string  | Product code              |
| CustomerID      | string  | Customer ID               |
| total\_quantity | int     | Sum of quantities         |
| total\_sales    | decimal | Sum of `Quantity Ã— Price` |

â–¶ï¸ Running the Pipeline
php artisan migrate
php artisan ingest:csv
php artisan preprocess:data
php artisan aggregate:quarterly

Notes:
ingest:csv â†’ expects file at storage/app/online_retail_II.csv

preprocess:data â†’ cleans invalid data in batches of 1000 rows

aggregate:quarterly â†’ uses MySQL YEAR() + QUARTER() for grouping
ğŸ§° Troubleshooting
Database connection error? Use DB_HOST=mysql and DB_PORT=3306 inside containers.

App canâ€™t connect from host? Use 127.0.0.1:3307.

Placeholder errors / slow inserts? Insert rows in chunks (1000 rows per batch).

Date parsing issues? Adjust STR_TO_DATE format string to match your CSV (dd/mm/yyyy HH:MM).

CSV not found? Ensure file is in ingestion/storage/app/online_retail_II.csv.

ğŸ—º Roadmap

REST API for aggregated data

Add CI/CD & container healthchecks

Deploy pipeline to cloud (AWS, GCP, Azure)

Add real-time streaming pipeline (Kafka, Spark)

Â© License & Acknowledgements

Dataset: Online Retail II â€” UCI Machine Learning Repository

Project developed for IU DLMDSEDE02 coursework
ğŸ‘¤ Maintainer
zahoormsc24
